{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2644ff-f5a4-4567-8be8-f1578c52156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.math import confusion_matrix\n",
    "\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f18a6fd-8ff6-4b04-baf2-947ac89b657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the image data from keras.datasets\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data(\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e55c861-3866-4729-9f4e-72eefdaa6f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to check the shape of the array\n",
    "xTrain.shape, yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "153f7826-4bc0-4d6c-8bdc-0640c7b31453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14901961\n",
      "  0.16862745 0.41176471 1.         0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.68235294 0.02352941 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16862745 0.54509804 0.87843137\n",
      "  0.88627451 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.98823529 0.61960784 0.05490196 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.69803922 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.23137255 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42745098 0.98823529 0.98823529\n",
      "  0.90196078 0.51764706 0.52156863 0.51764706 0.51764706 0.74117647\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.23137255 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.11372549 0.11372549\n",
      "  0.09411765 0.         0.         0.         0.         0.05490196\n",
      "  0.88627451 0.98823529 0.98823529 0.6745098  0.02745098 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33333333\n",
      "  0.95294118 0.98823529 0.98823529 0.56470588 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.34509804 0.74117647\n",
      "  0.98823529 0.98823529 0.98823529 0.05490196 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.35686275 0.83137255 0.96862745 0.98823529\n",
      "  0.98823529 0.98823529 0.8        0.03529412 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.1254902  0.49019608 0.75686275\n",
      "  0.75686275 0.75686275 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.93333333 0.4        0.10980392 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.87058824 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.69411765 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.8745098  0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 1.         0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12156863 0.48235294 0.20392157\n",
      "  0.17254902 0.17254902 0.17254902 0.17254902 0.56078431 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.3372549  0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.01960784 0.29411765 0.03529412 0.         0.         0.\n",
      "  0.         0.         0.         0.38431373 0.94901961 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.23921569\n",
      "  0.71764706 0.98823529 0.11372549 0.         0.         0.\n",
      "  0.         0.07058824 0.36078431 0.9372549  0.98823529 0.98823529\n",
      "  0.95294118 0.25490196 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81568627\n",
      "  0.98823529 0.98823529 0.57647059 0.5254902  0.5254902  0.5254902\n",
      "  0.5254902  0.79607843 0.99215686 0.98823529 0.98823529 0.7372549\n",
      "  0.3254902  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81568627\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.90196078 0.6        0.03137255\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.19215686\n",
      "  0.61568627 0.98823529 0.98823529 0.98823529 0.98823529 0.98823529\n",
      "  0.85098039 0.81176471 0.57254902 0.17647059 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.02745098 0.40392157 0.92156863 0.98823529 0.6745098  0.40392157\n",
      "  0.09411765 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3514b6840>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcDklEQVR4nO3df3DU9b3v8dcCyQqaLIaQXyVgAAUrEK9U0hRFlAxJOsPw63TAH3PA4+ARgy2i1ZuOirSdSYtnrKND8c69FepcwR8zQkaOpUeDCaMGekG4HNqaEm5aYkmCcie7IZgQyOf+wXXrSoJ+l928s8vzMfOdIbvfT/bt19Un3+zuNz7nnBMAAANsiPUAAIDLEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlkP8FW9vb06fvy40tLS5PP5rMcBAHjknFNHR4fy8vI0ZEj/5zmDLkDHjx9Xfn6+9RgAgEvU3NysMWPG9Hv/oAtQWlqaJOkWfV/DlGI8DQDAq7Pq0ft6O/z/8/7ELUAbNmzQM888o9bWVhUWFuqFF17QjBkzvnbdFz92G6YUDfMRIABIOP//CqNf9zJKXN6E8Nprr2nNmjVau3atPvroIxUWFqq0tFQnTpyIx8MBABJQXAL07LPPasWKFbr33nv17W9/Wy+++KJGjBihl156KR4PBwBIQDEP0JkzZ7R//36VlJT840GGDFFJSYnq6+sv2L+7u1uhUChiAwAkv5gH6LPPPtO5c+eUnZ0dcXt2drZaW1sv2L+qqkqBQCC88Q44ALg8mH8QtbKyUsFgMLw1NzdbjwQAGAAxfxdcZmamhg4dqra2tojb29ralJOTc8H+fr9ffr8/1mMAAAa5mJ8Bpaamavr06aqpqQnf1tvbq5qaGhUXF8f64QAACSounwNas2aNli1bpu985zuaMWOGnnvuOXV2duree++Nx8MBABJQXAK0ZMkSffrpp3rqqafU2tqqG2+8UTt37rzgjQkAgMuXzznnrIf4slAopEAgoNmaz5UQACABnXU9qlW1gsGg0tPT+93P/F1wAIDLEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBimPUAQDz4pt8Q1breVO//Sfx99pWe1/zxoV97XtPjznlek4zmHP4nz2uunN8S1WP1dnVFtQ7fDGdAAAATBAgAYCLmAXr66afl8/kitsmTJ8f6YQAACS4urwHdcMMNevfdd//xIMN4qQkAECkuZRg2bJhycnLi8a0BAEkiLq8BHTlyRHl5eRo/frzuvvtuHTt2rN99u7u7FQqFIjYAQPKLeYCKioq0efNm7dy5Uxs3blRTU5NuvfVWdXR09Ll/VVWVAoFAeMvPz4/1SACAQSjmASovL9cPfvADTZs2TaWlpXr77bfV3t6u119/vc/9KysrFQwGw1tzc3OsRwIADEJxf3fAyJEjdd1116mxsbHP+/1+v/x+f7zHAAAMMnH/HNCpU6d09OhR5ebmxvuhAAAJJOYBevTRR1VXV6e//vWv+vDDD7Vw4UINHTpUd955Z6wfCgCQwGL+I7hPPvlEd955p06ePKnRo0frlltu0Z49ezR69OhYPxQAIIH5nHPOeogvC4VCCgQCmq35GuZLsR4HMeaKCz2vObI81fOaX92x1fMaSUrxnfW8pmR43+/wvJghUfzwoVe9ntfgvBs//Jeo1hWsPO55zbnPTkb1WMnkrOtRraoVDAaVnp7e735cCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBH3X0gHfJn7+f/1vObjyW/GYRJcTg5+76Wo1pUWPeh5jf/fuRjpN8UZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwNWwMqL/X5ntfNDn2c/Snvsvvec2/vL3C+wP5vC+Ri2JNlL570188r9l0zX/EYRIkM86AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUA2rsL/Z5XrPw9TvjMEnffGd6PK+5tmlvHCax1Z45yvOad/ekeV5TMrzD85po3PGfS6Jal/7eHz2v6Y3qkS5PnAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GCkGlOs543nNuYbGOEyCi2lbdJ3nNVNTq6N4JH8Ua7w7fjwjqnVXnf4/MZ4EX8YZEADABAECAJjwHKDdu3dr3rx5ysvLk8/n0/bt2yPud87pqaeeUm5uroYPH66SkhIdOXIkVvMCAJKE5wB1dnaqsLBQGzZs6PP+9evX6/nnn9eLL76ovXv36sorr1Rpaam6uroueVgAQPLw/CaE8vJylZeX93mfc07PPfecnnjiCc2fP1+S9PLLLys7O1vbt2/X0qVLL21aAEDSiOlrQE1NTWptbVVJSUn4tkAgoKKiItXX1/e5pru7W6FQKGIDACS/mAaotbVVkpSdnR1xe3Z2dvi+r6qqqlIgEAhv+fn5sRwJADBImb8LrrKyUsFgMLw1NzdbjwQAGAAxDVBOTo4kqa2tLeL2tra28H1f5ff7lZ6eHrEBAJJfTANUUFCgnJwc1dTUhG8LhULau3eviouLY/lQAIAE5/ldcKdOnVJj4z8ujdLU1KSDBw8qIyNDY8eO1erVq/Xzn/9c1157rQoKCvTkk08qLy9PCxYsiOXcAIAE5zlA+/bt0+233x7+es2aNZKkZcuWafPmzXrsscfU2dmp+++/X+3t7brlllu0c+dOXXHFFbGbGgCQ8HzOOWc9xJeFQiEFAgHN1nwN86VYjwMktE9XRvej78n3fOx5zaZr/iOqxxoICwvLolp37rOTMZ7k8nDW9ahW1QoGgxd9Xd/8XXAAgMsTAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHj+dQwALt2JVd/zvGbZyrc9r7kn/d88r5GktCGpUa0bCD/79CbPa1z3mThMgkvFGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKLkWJADb1hkuc1f7n3as9rbrvlsOc1A2lH/gue1/SqN4pHGriLijb2nPW8ZsnGRzyvGbutzfOa3o6jntcg/jgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDFSRM3NvNHzmuWbtnleM//KzzyvGfyS7+9+P2xc4nnNt375oec15zyvwGCVfP8VAAASAgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRYkANlfO8ZkgS/j0pxTfU85oe74duQO283vuFZm+9u8LzmsArezyvweCUfP9lAwASAgECAJjwHKDdu3dr3rx5ysvLk8/n0/bt2yPuX758uXw+X8RWVlYWq3kBAEnCc4A6OztVWFioDRs29LtPWVmZWlpawtvWrVsvaUgAQPLx/CaE8vJylZeXX3Qfv9+vnJycqIcCACS/uLwGVFtbq6ysLE2aNEkrV67UyZMn+923u7tboVAoYgMAJL+YB6isrEwvv/yyampq9Mtf/lJ1dXUqLy/XuXN9/yb3qqoqBQKB8Jafnx/rkQAAg1DMPwe0dOnS8J+nTp2qadOmacKECaqtrdWcOXMu2L+yslJr1qwJfx0KhYgQAFwG4v427PHjxyszM1ONjY193u/3+5Wenh6xAQCSX9wD9Mknn+jkyZPKzc2N90MBABKI5x/BnTp1KuJspqmpSQcPHlRGRoYyMjK0bt06LV68WDk5OTp69Kgee+wxTZw4UaWlpTEdHACQ2DwHaN++fbr99tvDX3/x+s2yZcu0ceNGHTp0SL/97W/V3t6uvLw8zZ07Vz/72c/k9/tjNzUAIOF5DtDs2bPlXP9XRfz9739/SQMhcfg+OOh5zW8WeL8qxn9dPsrzmrG/P+N5jSQN/fxsVOsGqyP3pUS17uOyjTGeBLgQ14IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiZj/Sm7gYs796S+e14x/LA6DXCauPzI6uoXeL1oOeMYZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRAkmsbdFE6xGAfnEGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkScbn93te0/6D/xLVY11d/UfPa3o7OqJ6LEgtj3zP85rqH66P8tG8P48ArzgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDHSQaxr3gzPawKPHvO8pm7iC57XSNLC/3Wn90UNyXcx0mG5OZ7X/P2fxnte89pD/+Z5Td6wgbuoaNu5bs9rUj53cZgEiYIzIACACQIEADDhKUBVVVW6+eablZaWpqysLC1YsEANDQ0R+3R1damiokKjRo3SVVddpcWLF6utrS2mQwMAEp+nANXV1amiokJ79uzRO++8o56eHs2dO1ednZ3hfR5++GG99dZbeuONN1RXV6fjx49r0aJFMR8cAJDYPL0JYefOnRFfb968WVlZWdq/f79mzZqlYDCo3/zmN9qyZYvuuOMOSdKmTZt0/fXXa8+ePfrud78bu8kBAAntkl4DCgaDkqSMjAxJ0v79+9XT06OSkpLwPpMnT9bYsWNVX1/f5/fo7u5WKBSK2AAAyS/qAPX29mr16tWaOXOmpkyZIklqbW1VamqqRo4cGbFvdna2Wltb+/w+VVVVCgQC4S0/Pz/akQAACSTqAFVUVOjw4cN69dVXL2mAyspKBYPB8Nbc3HxJ3w8AkBii+iDqqlWrtGPHDu3evVtjxowJ356Tk6MzZ86ovb094iyora1NOTl9f1jP7/fL7x+4D8sBAAYHT2dAzjmtWrVK27Zt065du1RQUBBx//Tp05WSkqKamprwbQ0NDTp27JiKi4tjMzEAICl4OgOqqKjQli1bVF1drbS0tPDrOoFAQMOHD1cgENB9992nNWvWKCMjQ+np6XrooYdUXFzMO+AAABE8BWjjxo2SpNmzZ0fcvmnTJi1fvlyS9Ktf/UpDhgzR4sWL1d3drdLSUv3617+OybAAgOThc84NqqsBhkIhBQIBzdZ8DfOlWI9j6rZDn3te88iow3GYpG/Xv/uv3hedSr5/p0u/1/dHDC5mXdYBz2t61et5TbSW/bXU85rGTZM8rxn1P7wfOwx+Z12PalWtYDCo9PT0fvfjWnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEdVvRAUk6c8l/816hATm/e9+9V3ef3Pwir3/7HmNJE1cccTzmlGdXNka3nAGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkg9iuH870vOblB2d4XvO/Z77keU2y+p+hfM9rWnpGel7z0kfe/91O/O/nPK8Z/8FBz2skqTeqVYA3nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GOkgNrT2I89rCv4wwvOa6T/8kec1kvTbf33O85opqT7Pa+74zyWe1wRrczyvkaRxr/3d85qzTX/zvOZa7fe8Bkg2nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ8zjlnPcSXhUIhBQIBzdZ8DfOlWI8DAPDorOtRraoVDAaVnp7e736cAQEATBAgAIAJTwGqqqrSzTffrLS0NGVlZWnBggVqaGiI2Gf27Nny+XwR2wMPPBDToQEAic9TgOrq6lRRUaE9e/bonXfeUU9Pj+bOnavOzs6I/VasWKGWlpbwtn79+pgODQBIfJ5+I+rOnTsjvt68ebOysrK0f/9+zZo1K3z7iBEjlJMT3W+kBABcHi7pNaBgMChJysjIiLj9lVdeUWZmpqZMmaLKykqdPn263+/R3d2tUCgUsQEAkp+nM6Av6+3t1erVqzVz5kxNmTIlfPtdd92lcePGKS8vT4cOHdLjjz+uhoYGvfnmm31+n6qqKq1bty7aMQAACSrqzwGtXLlSv/vd7/T+++9rzJgx/e63a9cuzZkzR42NjZowYcIF93d3d6u7uzv8dSgUUn5+Pp8DAoAE9U0/BxTVGdCqVau0Y8cO7d69+6LxkaSioiJJ6jdAfr9ffr8/mjEAAAnMU4Ccc3rooYe0bds21dbWqqCg4GvXHDx4UJKUm5sb1YAAgOTkKUAVFRXasmWLqqurlZaWptbWVklSIBDQ8OHDdfToUW3ZskXf//73NWrUKB06dEgPP/ywZs2apWnTpsXlHwAAkJg8vQbk8/n6vH3Tpk1avny5mpubdc899+jw4cPq7OxUfn6+Fi5cqCeeeOKiPwf8Mq4FBwCJLS6vAX1dq/Lz81VXV+flWwIALlNcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKY9QBf5ZyTJJ1Vj+SMhwEAeHZWPZL+8f/z/gy6AHV0dEiS3tfbxpMAAC5FR0eHAoFAv/f73NclaoD19vbq+PHjSktLk8/ni7gvFAopPz9fzc3NSk9PN5rQHsfhPI7DeRyH8zgO5w2G4+CcU0dHh/Ly8jRkSP+v9Ay6M6AhQ4ZozJgxF90nPT39sn6CfYHjcB7H4TyOw3kch/Osj8PFzny+wJsQAAAmCBAAwERCBcjv92vt2rXy+/3Wo5jiOJzHcTiP43Aex+G8RDoOg+5NCACAy0NCnQEBAJIHAQIAmCBAAAATBAgAYCJhArRhwwZdc801uuKKK1RUVKQ//OEP1iMNuKefflo+ny9imzx5svVYcbd7927NmzdPeXl58vl82r59e8T9zjk99dRTys3N1fDhw1VSUqIjR47YDBtHX3ccli9ffsHzo6yszGbYOKmqqtLNN9+stLQ0ZWVlacGCBWpoaIjYp6urSxUVFRo1apSuuuoqLV68WG1tbUYTx8c3OQ6zZ8++4PnwwAMPGE3ct4QI0GuvvaY1a9Zo7dq1+uijj1RYWKjS0lKdOHHCerQBd8MNN6ilpSW8vf/++9YjxV1nZ6cKCwu1YcOGPu9fv369nn/+eb344ovau3evrrzySpWWlqqrq2uAJ42vrzsOklRWVhbx/Ni6desAThh/dXV1qqio0J49e/TOO++op6dHc+fOVWdnZ3ifhx9+WG+99ZbeeOMN1dXV6fjx41q0aJHh1LH3TY6DJK1YsSLi+bB+/XqjifvhEsCMGTNcRUVF+Otz5865vLw8V1VVZTjVwFu7dq0rLCy0HsOUJLdt27bw1729vS4nJ8c988wz4dva29ud3+93W7duNZhwYHz1ODjn3LJly9z8+fNN5rFy4sQJJ8nV1dU5587/u09JSXFvvPFGeJ8///nPTpKrr6+3GjPuvnocnHPutttucz/60Y/shvoGBv0Z0JkzZ7R//36VlJSEbxsyZIhKSkpUX19vOJmNI0eOKC8vT+PHj9fdd9+tY8eOWY9kqqmpSa2trRHPj0AgoKKiosvy+VFbW6usrCxNmjRJK1eu1MmTJ61HiqtgMChJysjIkCTt379fPT09Ec+HyZMna+zYsUn9fPjqcfjCK6+8oszMTE2ZMkWVlZU6ffq0xXj9GnQXI/2qzz77TOfOnVN2dnbE7dnZ2fr444+NprJRVFSkzZs3a9KkSWppadG6det066236vDhw0pLS7Mez0Rra6sk9fn8+OK+y0VZWZkWLVqkgoICHT16VD/5yU9UXl6u+vp6DR061Hq8mOvt7dXq1as1c+ZMTZkyRdL550NqaqpGjhwZsW8yPx/6Og6SdNddd2ncuHHKy8vToUOH9Pjjj6uhoUFvvvmm4bSRBn2A8A/l5eXhP0+bNk1FRUUaN26cXn/9dd13332Gk2EwWLp0afjPU6dO1bRp0zRhwgTV1tZqzpw5hpPFR0VFhQ4fPnxZvA56Mf0dh/vvvz/856lTpyo3N1dz5szR0aNHNWHChIEes0+D/kdwmZmZGjp06AXvYmlra1NOTo7RVIPDyJEjdd1116mxsdF6FDNfPAd4flxo/PjxyszMTMrnx6pVq7Rjxw699957Eb++JScnR2fOnFF7e3vE/sn6fOjvOPSlqKhIkgbV82HQByg1NVXTp09XTU1N+Lbe3l7V1NSouLjYcDJ7p06d0tGjR5Wbm2s9ipmCggLl5OREPD9CoZD27t172T8/PvnkE508eTKpnh/OOa1atUrbtm3Trl27VFBQEHH/9OnTlZKSEvF8aGho0LFjx5Lq+fB1x6EvBw8elKTB9XywfhfEN/Hqq686v9/vNm/e7P70pz+5+++/340cOdK1trZajzagHnnkEVdbW+uamprcBx984EpKSlxmZqY7ceKE9Whx1dHR4Q4cOOAOHDjgJLlnn33WHThwwP3tb39zzjn3i1/8wo0cOdJVV1e7Q4cOufnz57uCggL3+eefG08eWxc7Dh0dHe7RRx919fX1rqmpyb377rvupptuctdee63r6uqyHj1mVq5c6QKBgKutrXUtLS3h7fTp0+F9HnjgATd27Fi3a9cut2/fPldcXOyKi4sNp469rzsOjY2N7qc//anbt2+fa2pqctXV1W78+PFu1qxZxpNHSogAOefcCy+84MaOHetSU1PdjBkz3J49e6xHGnBLlixxubm5LjU11X3rW99yS5YscY2NjdZjxd17773nJF2wLVu2zDl3/q3YTz75pMvOznZ+v9/NmTPHNTQ02A4dBxc7DqdPn3Zz5851o0ePdikpKW7cuHFuxYoVSfeXtL7++SW5TZs2hff5/PPP3YMPPuiuvvpqN2LECLdw4ULX0tJiN3QcfN1xOHbsmJs1a5bLyMhwfr/fTZw40f34xz92wWDQdvCv4NcxAABMDPrXgAAAyYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMPH/AOet0kpmDjLBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print some images from this dataset\n",
    "print(xTrain[7])\n",
    "plt.imshow(xTrain[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342b8cd1-b998-4e99-83c7-7f836f174a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to normalize the data to get the highest accuracy\n",
    "xTrain = xTrain / 255.0\n",
    "xTest = xTest / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51ab4765-46b3-48aa-be8f-f140e75db016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 626us/step - accuracy: 0.8358 - loss: 0.5575\n",
      "Epoch 2/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.9598 - loss: 0.1317\n",
      "Epoch 3/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.9733 - loss: 0.0879\n",
      "Epoch 4/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9812 - loss: 0.0637\n",
      "Epoch 5/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.9856 - loss: 0.0476\n",
      "Epoch 6/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.9876 - loss: 0.0398\n",
      "Epoch 7/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.9890 - loss: 0.0350\n",
      "Epoch 8/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.9913 - loss: 0.0276\n",
      "Epoch 9/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9918 - loss: 0.0241\n",
      "Epoch 10/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.9926 - loss: 0.0220\n",
      "Epoch 11/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9942 - loss: 0.0197\n",
      "Epoch 12/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.9946 - loss: 0.0176\n",
      "Epoch 13/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.9939 - loss: 0.0174\n",
      "Epoch 14/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.9956 - loss: 0.0131\n",
      "Epoch 15/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.9941 - loss: 0.0183\n",
      "Epoch 16/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.9957 - loss: 0.0131\n",
      "Epoch 17/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.9958 - loss: 0.0116\n",
      "Epoch 18/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.9952 - loss: 0.0142\n",
      "Epoch 19/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.9954 - loss: 0.0122\n",
      "Epoch 20/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.9964 - loss: 0.0111\n",
      "Epoch 21/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.9959 - loss: 0.0119\n",
      "Epoch 22/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.9961 - loss: 0.0121\n",
      "Epoch 23/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.9972 - loss: 0.0085\n",
      "Epoch 24/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.9964 - loss: 0.0104\n",
      "Epoch 25/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.9960 - loss: 0.0133\n",
      "Epoch 26/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.9970 - loss: 0.0096\n",
      "Epoch 27/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9964 - loss: 0.0102\n",
      "Epoch 28/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9975 - loss: 0.0072\n",
      "Epoch 29/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.9972 - loss: 0.0086\n",
      "Epoch 30/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.9981 - loss: 0.0058\n",
      "Epoch 31/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.9981 - loss: 0.0055\n",
      "Epoch 32/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9978 - loss: 0.0070\n",
      "Epoch 33/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.9976 - loss: 0.0064\n",
      "Epoch 34/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9975 - loss: 0.0070\n",
      "Epoch 35/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.9979 - loss: 0.0073\n",
      "Epoch 36/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.9977 - loss: 0.0067\n",
      "Epoch 37/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.9976 - loss: 0.0081\n",
      "Epoch 38/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.9974 - loss: 0.0082\n",
      "Epoch 39/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 40/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9980 - loss: 0.0074\n",
      "Epoch 41/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.9976 - loss: 0.0067\n",
      "Epoch 42/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 43/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.9986 - loss: 0.0044\n",
      "Epoch 44/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.9985 - loss: 0.0059\n",
      "Epoch 45/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.9981 - loss: 0.0057\n",
      "Epoch 46/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.9978 - loss: 0.0073\n",
      "Epoch 47/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.9986 - loss: 0.0049\n",
      "Epoch 48/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.9975 - loss: 0.0071\n",
      "Epoch 49/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.9987 - loss: 0.0043\n",
      "Epoch 50/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.9984 - loss: 0.0057\n",
      "Epoch 51/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9984 - loss: 0.0058\n",
      "Epoch 52/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.9989 - loss: 0.0040\n",
      "Epoch 53/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.9983 - loss: 0.0057\n",
      "Epoch 54/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.9984 - loss: 0.0050\n",
      "Epoch 55/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.9978 - loss: 0.0083\n",
      "Epoch 56/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9986 - loss: 0.0038\n",
      "Epoch 57/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.9984 - loss: 0.0051\n",
      "Epoch 58/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.9985 - loss: 0.0053\n",
      "Epoch 59/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.9985 - loss: 0.0049\n",
      "Epoch 60/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.9987 - loss: 0.0040\n",
      "Epoch 61/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.9989 - loss: 0.0039\n",
      "Epoch 62/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.9986 - loss: 0.0040\n",
      "Epoch 63/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.9985 - loss: 0.0049\n",
      "Epoch 64/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 65/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.9985 - loss: 0.0046\n",
      "Epoch 66/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.9984 - loss: 0.0060\n",
      "Epoch 67/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.9992 - loss: 0.0029\n",
      "Epoch 68/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.9986 - loss: 0.0055\n",
      "Epoch 69/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.9988 - loss: 0.0045\n",
      "Epoch 70/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.9991 - loss: 0.0037\n",
      "Epoch 71/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.9984 - loss: 0.0054\n",
      "Epoch 72/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.9992 - loss: 0.0028\n",
      "Epoch 73/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.9984 - loss: 0.0052\n",
      "Epoch 74/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.9987 - loss: 0.0049\n",
      "Epoch 75/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9992 - loss: 0.0026\n",
      "Epoch 76/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.9988 - loss: 0.0046\n",
      "Epoch 77/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.9985 - loss: 0.0052\n",
      "Epoch 78/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 79/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.9990 - loss: 0.0031\n",
      "Epoch 80/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.9987 - loss: 0.0038\n",
      "Epoch 81/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.9989 - loss: 0.0035\n",
      "Epoch 82/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.9993 - loss: 0.0031\n",
      "Epoch 83/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.9988 - loss: 0.0039\n",
      "Epoch 84/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 85/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.9993 - loss: 0.0025\n",
      "Epoch 86/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.9988 - loss: 0.0060\n",
      "Epoch 87/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.9992 - loss: 0.0022\n",
      "Epoch 88/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.9994 - loss: 0.0017\n",
      "Epoch 89/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.9982 - loss: 0.0060\n",
      "Epoch 90/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9989 - loss: 0.0042\n",
      "Epoch 91/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9987 - loss: 0.0056\n",
      "Epoch 92/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 93/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.9987 - loss: 0.0052\n",
      "Epoch 94/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 95/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.9988 - loss: 0.0051\n",
      "Epoch 96/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.9990 - loss: 0.0034\n",
      "Epoch 97/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.9989 - loss: 0.0036\n",
      "Epoch 98/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.9992 - loss: 0.0039\n",
      "Epoch 99/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.9989 - loss: 0.0042\n",
      "Epoch 100/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9994 - loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "# compile the model\n",
    "model.compile(\n",
    "    loss = tf.losses.SparseCategoricalCrossentropy,\n",
    "    optimizer = tf.optimizers.Adam(learning_rate = 4.466e-04),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# we need to fit into the model\n",
    "model.fit(xTrain, yTrain, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c9c400-5d86-47f2-88e5-4a5379671c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step - accuracy: 0.9756 - loss: 0.2029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17095761001110077, 0.9805999994277954]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c8e74f8-5323-40e5-97e8-d07030eeabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "The predicted class is: 3\n"
     ]
    }
   ],
   "source": [
    "sample = np.expand_dims(xTrain[7], axis=0)\n",
    "\n",
    "out = model.predict(sample)\n",
    "\n",
    "out = np.squeeze(out)\n",
    "\n",
    "samplePrediction = np.argmax(out)\n",
    "\n",
    "print(f\"The predicted class is: {samplePrediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
